{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Entropy(data):\n",
    "    ct, res = 0., 0.\n",
    "    for a in data:\n",
    "        ct+=1\n",
    "    d = dict((w[-1],0) for w in data)\n",
    "    for w in data:\n",
    "        d[w[-1]]+=1.0\n",
    "    for k,v in d.items():\n",
    "        p = d[k]/ct\n",
    "        res -= p*math.log(p)\n",
    "        d[k]=p\n",
    "    return res\n",
    "    \n",
    "def EntropyByIndex(data , index):\n",
    "    d = dict((w[index],0) for w in data)\n",
    "    res = 0\n",
    "    for w in data:\n",
    "        d[w[index]]+=1.0\n",
    "    for k,v in d.items():\n",
    "        p = d[k]/len(data)\n",
    "        #kent=p*Entropy([w for w in data if w[index]==k])\n",
    "        kent = p*EntropyByIndexValue(data, index, k)\n",
    "        res += kent\n",
    "        d[k]=kent\n",
    "    return res\n",
    "\n",
    "def EntropyByIndexValue(data, index, k):\n",
    "    ct, res = 0., 0.\n",
    "    for w in data:\n",
    "        if w[index]==k:\n",
    "            ct+=1\n",
    "    d = dict((w[-1],0) for w in data if w[index]==k)\n",
    "    for w in data:\n",
    "        if(w[index]==k):\n",
    "            d[w[-1]]+=1.0\n",
    "    for k,v in d.items():\n",
    "        p = d[k]/ct\n",
    "        res -= p*math.log(p)\n",
    "        d[k]=p\n",
    "    return res\n",
    "\n",
    "\n",
    "def MinEntropy(data, attr):   #-->(attr[i], entropy)\n",
    "    d = dict((n,EntropyByIndex(data, n)) for n in attr)\n",
    "    return min(d, key=d.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "import math\n",
    "def SplitByColumn(list2d, n):\n",
    "    d ={}\n",
    "    for i in range(0, len(list2d)):\n",
    "        d.setdefault(list2d[i][n], []).append(list2d[i])\n",
    "    return d\n",
    "\n",
    "\n",
    "\n",
    "class Treenode():\n",
    "    def __init__(self, maxdepth=2, key=None):\n",
    "        self.key = key\n",
    "        self.childs={}       #словарь ключ-потомок\n",
    "        self.attr = []\n",
    "        self.data=[]         #данные узла. в root - все\n",
    "        self.depth=0\n",
    "        self.maxdepth=maxdepth\n",
    "        self.splitIndex=0\n",
    "    def DefaultF(data, attr):\n",
    "        return attr[0]\n",
    "       \n",
    "        \n",
    "    def SetData(self, data, f =None):\n",
    "        self.attr= [i for i in range(len(data[0])-1)]\n",
    "        if not f:\n",
    "            f = Treenode.DefaultF\n",
    "        self._addData(data, self.attr, f)\n",
    "    \n",
    "    def PredictList(self, attr):\n",
    "        k=  self.splitIndex\n",
    "        if k < len(attr) and attr[k] in self.childs:\n",
    "            return self.childs[attr[k]].PredictList(attr)\n",
    "        else:\n",
    "            return [row[-1] for row in self.data]\n",
    "    def PredictW(self, attr):\n",
    "        k=self.splitIndex\n",
    "        if k < len(attr) and attr[k] in self.childs:\n",
    "            return self.childs[attr[k]].PredictW(attr)\n",
    "        else:\n",
    "            d={}\n",
    "            for w in self.data:\n",
    "                d.setdefault(w[-1],0)\n",
    "                d[w[-1]]+=1\n",
    "            return max(d,key=d.get)\n",
    "    \n",
    "    def Predict(self, attr):\n",
    "        #tt=self._PredictProb(attr)\n",
    "        #return max(tt, key=tt.get)\n",
    "        #return self.PredictW(attr)\n",
    "        l = self.PredictList(attr)\n",
    "        return max(set(l), key=l.count)\n",
    "    \n",
    "    def _addData(self, data, attr, f):\n",
    "        self.data = data\n",
    "        if len(attr)!=0 and self.depth!=self.maxdepth:\n",
    "            self.splitIndex = f(data, attr)\n",
    "            self.entropy=EntropyByIndex(data,self.splitIndex)\n",
    "            self.attr = [v for v in attr if self.splitIndex!=v]\n",
    "            d = SplitByColumn(data, self.splitIndex)\n",
    "            for k,v in d.items():\n",
    "                ch = self.childs.setdefault(k,Treenode(self.maxdepth, k))\n",
    "                ch.depth = self.depth+1\n",
    "                ch._addData(v, self.attr,f)           \n",
    "        else:\n",
    "            self.data = data\n",
    "    \n",
    "    def _dataRepr(self):\n",
    "        prefix = 2*self.depth * \"-\"\n",
    "        if len(self.childs)==0:\n",
    "            return prefix+ \">>\" + str(self.data) + \"\\n\"\n",
    "        res=\"\"\n",
    "        for k,v in self.childs.items():\n",
    "            #res += self.depth * \" \" + f\"depth: {self.depth}, key:{str(k)} \" + \"\\n\" + self.depth * \" \" + v._dataRepr() + \"\\n\"\n",
    "            res+= prefix + f\"k[{self.splitIndex}]={k}, entropy={self.entropy}\\n\" + v._dataRepr()\n",
    "        return res\n",
    "    def __repr__(self):\n",
    "        return self._dataRepr()\n",
    "    def Count(self):\n",
    "        res=0\n",
    "        if(len(self.childs)!=0):\n",
    "            for k,v in self.childs.items():\n",
    "                res+=v.Count()\n",
    "        else:\n",
    "            if self.data:\n",
    "                res+=len(self.data)\n",
    "        return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
